---
title: "Paper accepted for publication in the proceedings of ECCV2024"
date: 2024-7-1
summary: Our paper "SparseRadNet Sparse Perception Neural Network on Subsampled Radar Data" has been accepted for publication in the proceedings of ECCV2024!
image: ./assets/images/news/news19.png
categories: [Paper, ECCV2024]
tags: []
main_url: ./news/2024-7-1.html
links:
  - label: "Read more"
    url: "./news/2024-7-1.html"
  - label: "Paper"
    url: "https://arxiv.org/abs/2406.10600"
  - label: "Project page"
    url: "https://osvia.org/Sparse-RadNet/"
---

Our paper "SparseRadNet: Sparse Perception Neural Network on Subsampled Radar Data" by Jialong Wu, Mirko Meuter, Markus Schoeler and Matthias Rottmann has been accepted for publication in the proceedings of ECCV2024!
<br><br>
Radar-based perception has gained increasing attention in autonomous driving, yet the inherent sparsity of radars poses challenges. Radar raw data often contains excessive noise, whereas radar point clouds retain only limited information. In this work, we holistically treat the sparse nature of radar data by introducing an adaptive subsampling method together with a tailored network architecture that exploits the sparsity patterns to discover global and local dependencies in the radar signal. Our subsampling module selects a subset of pixels from range-doppler (RD) spectra that contribute most to the downstream perception tasks. To improve the feature extraction on sparse subsampled data, we propose a new way of applying graph neural networks on radar data and design a novel two-branch backbone to capture both global and local neighbor information. An attentive fusion module is applied to combine features from both branches. Experiments on the RADIal dataset show that our SparseRadNet exceeds state-of-the-art (SOTA) performance in object detection and achieves close to SOTA accuracy in freespace segmentation, meanwhile using only 3% of sparse subsampled input data.
<br><br>
The paper is available here: https://arxiv.org/abs/2406.10600 